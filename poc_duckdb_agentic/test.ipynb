{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MInd steps for the automation workflow in large steps \n",
    "\n",
    "1. the agent will get the name of a new data table from duckdb.\n",
    "2. extract the new table schema and couple of rows from it.\n",
    "3. make sure all the needed fields are there even if there is a slight naming difference.\n",
    "4. create separate nodes based on functionalities for analytical separation.\n",
    "5. extract predefined analysis table schemas in the prompts.\n",
    "6. insert those analysis into the tables with the right names in the db."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "import duckdb\n",
    "# conn = duckdb.connect(\"test_duckdb.duckdb\")\n",
    "duckdb.sql(\"INSTALL spatial;\")\n",
    "duckdb.sql(\"LOAD spatial;\")\n",
    "\n",
    "duckdb_uri = 'duckdb:///test_duckdb.duckdb'\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# get the SQL Agent from langchain_community\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "# from pydantic_ai import Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/Anas_TrendSphere/.venv/lib/python3.11/site-packages/duckdb_engine/__init__.py:174: DuckDBEngineWarning: duckdb-engine doesn't yet support reflection on indices\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "db = SQLDatabase.from_uri(duckdb_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supabase storage credentials\n",
    "BUCKET_URL = os.getenv(\"BUCKET_URL\")\n",
    "ENDPOINT_URL = os.getenv(\"ENDPOINT_URL\")\n",
    "\n",
    "AWS_ACCESS_KEY_ID = os.getenv(\"AWS_ACCESS_KEY_ID\")\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    "AWS_REGION = os.getenv(\"AWS_REGION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┐\n",
       "│ Success │\n",
       "│ boolean │\n",
       "├─────────┤\n",
       "│ true    │\n",
       "└─────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\n",
    "    f\"\"\"\n",
    "    DROP SECRET IF EXISTS supabase_storage;\n",
    "    CREATE SECRET supabase_storage (\n",
    "        TYPE S3,\n",
    "        KEY_ID '{AWS_ACCESS_KEY_ID}',\n",
    "        SECRET '{AWS_SECRET_ACCESS_KEY}',\n",
    "        ENDPOINT '{ENDPOINT_URL}',                                            \n",
    "        REGION '{AWS_REGION}',\n",
    "        URL_STYLE 'path'\n",
    "    )\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn.execute(\n",
    "#     f\"\"\"\n",
    "#     create table restaurant_info as select * from st_read('{BUCKET_URL}')\n",
    "#     \"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get the llm agent up with the db "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'duckdb'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.dialect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['restaurant_info']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_usable_table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QuerySQLDataBaseTool(description=\"Input to this tool is a detailed and correct SQL query, output is a result from the database. If the query is not correct, an error message will be returned. If an error is returned, rewrite the query, check the query, and try again. If you encounter an issue with Unknown column 'xxxx' in 'field list', use sql_db_schema to query the correct table fields.\", db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7f6f40bc2110>),\n",
       " InfoSQLDatabaseTool(description='Input to this tool is a comma-separated list of tables, output is the schema and sample rows for those tables. Be sure that the tables actually exist by calling sql_db_list_tables first! Example Input: table1, table2, table3', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7f6f40bc2110>),\n",
       " ListSQLDatabaseTool(db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7f6f40bc2110>),\n",
       " QuerySQLCheckerTool(description='Use this tool to double check if your query is correct before executing it. Always use this tool before executing a query with sql_db_query!', db=<langchain_community.utilities.sql_database.SQLDatabase object at 0x7f6f40bc2110>, llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f6f4073e750>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f6f4074aed0>, root_client=<openai.OpenAI object at 0x7f6f416d8050>, root_async_client=<openai.AsyncOpenAI object at 0x7f6f4073e910>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), llm_chain=LLMChain(verbose=False, prompt=PromptTemplate(input_variables=['dialect', 'query'], input_types={}, partial_variables={}, template='\\n{query}\\nDouble check the {dialect} query above for common mistakes, including:\\n- Using NOT IN with NULL values\\n- Using UNION when UNION ALL should have been used\\n- Using BETWEEN for exclusive ranges\\n- Data type mismatch in predicates\\n- Properly quoting identifiers\\n- Using the correct number of arguments for functions\\n- Casting to the correct data type\\n- Using the proper columns for joins\\n\\nIf there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\\n\\nOutput the final SQL query only.\\n\\nSQL Query: '), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7f6f4073e750>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7f6f4074aed0>, root_client=<openai.OpenAI object at 0x7f6f416d8050>, root_async_client=<openai.AsyncOpenAI object at 0x7f6f4073e910>, model_name='gpt-4o-mini', model_kwargs={}, openai_api_key=SecretStr('**********')), output_parser=StrOutputParser(), llm_kwargs={}))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tables_tool = next(tool for tool in tools if tool.name == \"sql_db_list_tables\")\n",
    "get_schema_tool = next(tool for tool in tools if tool.name == \"sql_db_schema\")\n",
    "db_query_tool = next(tool for tool in tools if tool.name == \"sql_db_query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restaurant_info\n"
     ]
    }
   ],
   "source": [
    "print(list_tables_tool.invoke(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE restaurant_info (\n",
      "\treference INTEGER, \n",
      "\tnumber INTEGER, \n",
      "\texternal_number VARCHAR, \n",
      "\tbranch_name VARCHAR, \n",
      "\tbranch_reference VARCHAR, \n",
      "\ttype VARCHAR, \n",
      "\tsource VARCHAR, \n",
      "\tstatus VARCHAR, \n",
      "\toriginal_order_reference VARCHAR, \n",
      "\tbusiness_date DATE, \n",
      "\tsubtotal FLOAT, \n",
      "\ttotal_price INTEGER, \n",
      "\ttotal_charge INTEGER, \n",
      "\tcoupon_code VARCHAR, \n",
      "\tcoupon_name VARCHAR, \n",
      "\tdiscount_name VARCHAR, \n",
      "\tdiscounts INTEGER, \n",
      "\tguests INTEGER, \n",
      "\ttax_exclusive_discount_amount FLOAT, \n",
      "\ttax_exclusive_total_charges INTEGER, \n",
      "\trounding INTEGER, \n",
      "\ttotal_taxes FLOAT, \n",
      "\tcreated_at TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tcreated_by VARCHAR, \n",
      "\taccepted_at VARCHAR, \n",
      "\topened_at TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tdue_at VARCHAR, \n",
      "\tclosed_at TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tclosed_by VARCHAR, \n",
      "\tcheck_number INTEGER, \n",
      "\ttags VARCHAR, \n",
      "\tcustomer_name VARCHAR, \n",
      "\tcustomer_dial_code VARCHAR, \n",
      "\tcustomer_phone VARCHAR, \n",
      "\tcustomer_address_delivery_zone_name VARCHAR, \n",
      "\tcustomer_address_name VARCHAR, \n",
      "\tcustomer_address_description VARCHAR, \n",
      "\treceipt_notes VARCHAR, \n",
      "\tkitchen_notes VARCHAR, \n",
      "\tkitchen_received_at VARCHAR, \n",
      "\tkitchen_done_at VARCHAR, \n",
      "\tpreparation_period VARCHAR, \n",
      "\t\"عمود1\" INTEGER\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from restaurant_info table:\n",
      "reference\tnumber\texternal_number\tbranch_name\tbranch_reference\ttype\tsource\tstatus\toriginal_order_reference\tbusiness_date\tsubtotal\ttotal_price\ttotal_charge\tcoupon_code\tcoupon_name\tdiscount_name\tdiscounts\tguests\ttax_exclusive_discount_amount\ttax_exclusive_total_charges\trounding\ttotal_taxes\tcreated_at\tcreated_by\taccepted_at\topened_at\tdue_at\tclosed_at\tclosed_by\tcheck_number\ttags\tcustomer_name\tcustomer_dial_code\tcustomer_phone\tcustomer_address_delivery_zone_name\tcustomer_address_name\tcustomer_address_description\treceipt_notes\tkitchen_notes\tkitchen_received_at\tkitchen_done_at\tpreparation_period\tعمود1\n",
      "293899\t91\t-\tفرع عنيزة\tB02\tDrive Thru\tCashier\tDone\t-\t2024-08-24\t87.82609\t101\t0\tNone\tNone\t-\t0\t1\t0.0\t0\t0\t13.17391\t2024-08-25 00:30:59\tahmed\t-\t2024-08-25 00:29:06\t-\t2024-08-25 00:30:08\tahmed\t208719\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t293899\n",
      "293898\t167\t-\tفرع الافق\tB01\tDrive Thru\tCashier\tDone\t-\t2024-08-24\t218.26087\t251\t0\tNone\tNone\t-\t0\t1\t0.0\t0\t0\t32.73912\t2024-08-25 00:29:35\tابو تقي\t-\t2024-08-25 00:28:47\t-\t2024-08-25 00:29:33\tابو تقي\t284726\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t293898\n",
      "293897\t166\t-\tفرع الافق\tB01\tDrive Thru\tCashier\tDone\t-\t2024-08-24\t6.08696\t7\t0\tNone\tNone\t-\t0\t1\t0.0\t0\t0\t0.91304\t2024-08-25 00:25:34\tابو تقي\t-\t2024-08-25 00:24:59\t-\t2024-08-25 00:25:01\tابو تقي\t284725\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t-\t293897\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "print(get_schema_tool.invoke(\"restaurant_info\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the nodes and different aspects using langgraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_check_system = \"\"\"You are a SQL expert with a strong attention to detail.\n",
    "Double check the DuckDB query for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "If there are any of the above mistakes, rewrite the query. If there are no mistakes, just reproduce the original query.\n",
    "\n",
    "You will call the appropriate tool to execute the query after running this check.\"\"\"\n",
    "\n",
    "query_check_prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", query_check_system), (\"placeholder\", \"{messages}\")]\n",
    ")\n",
    "\n",
    "query_check = query_check_prompt | llm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import AnyMessage, add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    table_name: str\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    sql_query: str\n",
    "    analytical_table_inserted_in: str\n",
    "    \n",
    "class OutState(TypedDict):\n",
    "    analytical_table_inserted_in: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_question(self, state: dict) -> dict:\n",
    "        \"\"\"Parse user question and identify relevant tables and columns.\"\"\"\n",
    "        raw_table = state['table_name']\n",
    "        schema = get_schema_tool.invoke(raw_table)\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", '''You are a senior Analytics Engineer specializing in creating optimized SQL queries that benefits the business different KPIs. \n",
    "Given a database table with data and database schema, identify columns that we can use to create the following metrics:\n",
    "- Daily sales\n",
    "\n",
    "Your response should be in the following JSON format:\n",
    "{{\n",
    "    \"is_relevant\": boolean,\n",
    "    \"relevant_tables\": [\n",
    "        {{\n",
    "            \"table_name\": string,\n",
    "            \"columns\": [string],\n",
    "            \"noun_columns\": [string]\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "'''),\n",
    "            (\"human\", \"===Database schema:\\n{schema}\\n\\n===User raw_table:\\n{raw_table}\\n\\nIdentify relevant tables and columns:\")\n",
    "        ])\n",
    "\n",
    "        output_parser = JsonOutputParser()\n",
    "        \n",
    "        response = self.llm_manager.invoke(prompt, schema=schema, question=question)\n",
    "        parsed_response = output_parser.parse(response)\n",
    "        return {\"parsed_question\": parsed_response}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"raw_ingested_table\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
